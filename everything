{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/url?q=https://www.reddit.com/r/MovieSuggestions/&sa=U&ved=0ahUKEwjvlMiR0dfcAhViNn0KHZJ8CAQQFggaMAE&usg=AOvVaw3_TfBfobWoxbxIh5NgBzXd\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-0250760ef4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mpostIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_postIDs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mclient_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"jhAffV3EzTf80A\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-0250760ef4e0>\u001b[0m in \u001b[0;36mget_postIDs\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mbegIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mendIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbegIndex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msubmissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegIndex\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mendIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "\n",
    "#client_id: jhAffV3EzTf80A\n",
    "#secret: f38Y5S9QTzm6y0LyG5UiU47sMKk\n",
    "#username: carameldeligh5\n",
    "#password: @Collingsworth5\n",
    "\n",
    "#scrapes google for top 10 links \n",
    "\n",
    "query = \"best movies of 2018 reddit\"\n",
    "# query = \"best places to eat in seattle reddit\"\n",
    "substring = \"comments/\"\n",
    "\n",
    "#FUNCTIONS \n",
    "\n",
    "#returns a list of post IDs \n",
    "def get_postIDs(query): \n",
    "    \n",
    "    page = requests.get(\"https://www.google.com/search?q=\" + query)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    urls = soup.select(\".r a\")\n",
    "    links = [\"https://www.google.com\" + url.get('href') for url in urls]\n",
    "    \n",
    "    #could be extra processing here (LOOK DOWN)\n",
    "    links = links[1:]\n",
    "    \n",
    "    submissions = []\n",
    "    for link in links:\n",
    "        print (link)\n",
    "        begIndex = link.index(substring) + 9\n",
    "        endIndex = begIndex + 6\n",
    "        submissions.append(link[begIndex : endIndex])\n",
    "    \n",
    "    return submissions\n",
    "        \n",
    "\n",
    "postIDs = get_postIDs(query)\n",
    "\n",
    "client_id = \"jhAffV3EzTf80A\"\n",
    "client_secret = \"f38Y5S9QTzm6y0LyG5UiU47sMKk\"\n",
    "username = \"carameldelight5\"\n",
    "password = \"@Collingsworth5\"\n",
    "\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     password=password,\n",
    "                     user_agent='testscript by /u/carameldelight5',\n",
    "                     username=username)\n",
    "                     \n",
    "\n",
    "\n",
    "# TODO: uncomment - iterates through 10 reddit posts & gets top level comments for each post\n",
    "\n",
    "# postCount = 0 \n",
    "\n",
    "# for postID in postIDs: \n",
    "    \n",
    "#     print (\"POST: \" + str(postCount))\n",
    "#     post = reddit.submission(id = postID)\n",
    "#     commentCount = 0\n",
    "\n",
    "#     for top_level_comment in post.comments:\n",
    "#         if isinstance(top_level_comment, MoreComments):\n",
    "#             continue\n",
    "#         print (\"    COMMENT : \" + str(commentCount) + \" SCORE: \" + top_level_comment.)\n",
    "#         print(\"    \" + top_level_comment.body)\n",
    "        \n",
    "#         commentCount += 1\n",
    "\n",
    "#     postCount += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST ID: 6n9xbi\n"
     ]
    }
   ],
   "source": [
    "#nlp test (Spacy vs TextBlob)\n",
    "\n",
    "#gets post \n",
    "testPostID = postIDs[0]\n",
    "testPost = reddit.submission(testPostID)\n",
    "print (\"POST ID: \" + testPostID)\n",
    "\n",
    "#gets top 5 comments from the test Post \n",
    "commentID = 0 \n",
    "testComments = testPost.comments[0:5]\n",
    "\n",
    "correctPlacesOverall = [\n",
    "    ['Big Mario\\'s', 'Hot Mama\\'s'], \n",
    "    ['Jacks BBQ', 'Radiator Whiskey', 'Tacos Chukis', 'Uneeda', 'Kylies', 'Albi', 'Mighty O', 'Molly Moons'],\n",
    "    ['Wood Shop BBQ', 'Red Mill', 'Tacos El Asadero', 'Sizzle Pie'],\n",
    "    ['Zippy\\'s', 'Fonda la Catarina', 'Pagliacci', 'Uptown Espresso', 'Full Tilt', 'Pho 99', 'Pho Hi-Ho', 'Shiro\\'s'],\n",
    "    ['Jack\\'s BBQ']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #gets post ID\n",
    "# testPostID = postIDs[0]\n",
    "# testPost = reddit.submission(testPostID)\n",
    "# testComment = testPost.comments[0]\n",
    "# print (\"id: \" + testPostID + )\n",
    "\n",
    "# print (\"score: \" + str(testComment.score))\n",
    "\n",
    "# nlp = spacy.load(\"en\")\n",
    "# testCommentEnt = nlp(testComment.body)\n",
    "\n",
    "# print (testComment.body)\n",
    "# print (testCommentEnt.ents)\n",
    "\n",
    "# for ent in testCommentEnt.ents: \n",
    "#     print(ent, end = \" \")\n",
    "#     print(ent.label_, end = \" \")\n",
    "#     print(ent.label, end = \" \")\n",
    "#     print(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMMENT:  For pizza you should check out a Big Mario's. My partner is from the east coast and she hates all of our pizza except for there and Hot Mama's.\n",
      "RESULT: Hot Mama's\n",
      "\n",
      "COMMENT:  BBQ for me would be Jacks BBQ or Radiator Whiskey. Tacos I would head to Tacos Chukis. Burgers I would go to Uneeda. Pizza is a toss up, if you want deep dish try Kylies in Fremont, for thin crust there are millions but Albi room is my personal favorite.  Coffee is Victrola by a longshot.  Donuts is Mighty O all the way.   I am not a huge dessert person but Molly Moons is always high on my ice cream list. \n",
      "\n",
      "RESULT: Radiator Whiskey\n",
      "RESULT: Tacos Chukis\n",
      "RESULT: Kylies\n",
      "RESULT: Donuts\n",
      "RESULT: Molly Moons\n",
      "\n",
      "COMMENT:  BBQ - Wood Shop BBQ on Jackson\n",
      "\n",
      "Burgers - Red Mill\n",
      "\n",
      "Mexican (Tacos) - Tacos El Asadero\n",
      "\n",
      "Pizza - Sizzle Pie\n",
      "\n",
      "\n",
      "COMMENT:  I wouldn't use Austin categories.  Different place, I wouldn't even put BBQ or breakfast tacos in there.  You gotta include pho, sushi, Thai, and maybe Indian.  \n",
      "\n",
      "Anyway...\n",
      "\n",
      "Burgers:  Zippy's\n",
      "\n",
      "Mexican:  Fonda la Catarina\n",
      "\n",
      "Pizza:  Pagliacci (too bad Red Star closed)\n",
      "\n",
      "Coffee:  Uptown Espresso\n",
      "\n",
      "Hot Dogs:  blech\n",
      "\n",
      "Dessert:  Full Tilt ice cream! \n",
      "\n",
      "Now to the real categories: \n",
      "\n",
      "Pho:  Pho 99 or Pho Hi-Ho\n",
      "\n",
      "Sushi:  Shiro's \n",
      "\n",
      "Thai:  dunno\n",
      "\n",
      "Indian:  I've heard the best places are on the East side and I don't ever go there.\n",
      "\n",
      "\n",
      "RESULT: Austin\n",
      "RESULT: Different\n",
      "RESULT: \n",
      "\n",
      "Burgers\n",
      "RESULT:  Pagliacci\n",
      "RESULT: Uptown Espresso\n",
      "RESULT: \n",
      "\n",
      "Dessert\n",
      "RESULT: \n",
      "\n",
      "Pho\n",
      "RESULT: Pho Hi-Ho\n",
      "\n",
      "Sushi\n",
      "RESULT: \n",
      "\n",
      "Thai:\n",
      "\n",
      "COMMENT:  Check out Jack's BBQ on Airport Way!\n",
      "RESULT: Jack\n"
     ]
    }
   ],
   "source": [
    "#SPACY PERFORMANCE \n",
    "\n",
    "#captures score (# correct/total)\n",
    "spacyScores = []\n",
    "\n",
    "#captures entities flagged correctly \n",
    "correctPlacesSpacy = []\n",
    "\n",
    "#loads spacy NLP object \n",
    "spacyNLP = spacy.load(\"en\")\n",
    "\n",
    "#iterate through comments \n",
    "commentIndex = 0 \n",
    "while commentIndex < 5: \n",
    "    \n",
    "    #resets score\n",
    "    spacyScore = 0 \n",
    "    \n",
    "    #get comment \n",
    "    testComment = testComments[commentIndex]\n",
    "    testNLP = nlp(testComment.body)\n",
    "    print(\"\\nCOMMENT: \",testComment.body)\n",
    "    \n",
    "    #get entities & updates score for relevant comment \n",
    "    for ent in testNLP.ents:\n",
    "        \n",
    "#         print (\"ENT:\", ent.text, \" LABEL:\", ent.label_)\n",
    "        if ent.label_ == \"PERSON\": \n",
    "            print ('RESULT:', ent.text)\n",
    "#             in correctPlacesOverall[commentIndex]: \n",
    "#             spacyScore += 1 \n",
    "            \n",
    "#     for token in testNLP: \n",
    "#         print (\"TOKEN:\", token.text, \" POS:\", token.pos_, \" TAG:\", token.tag_)\n",
    "            \n",
    "    spacyScores.append(spacyScore)\n",
    "    commentIndex += 1 \n",
    "    \n",
    "# commentIndex = 0 \n",
    "# while commentIndex < 5: \n",
    "#     spacyScores[commentIndex] = spacyScores[commentIndex]/len(correctPlacesOverall[commentIndex])\n",
    "#     commentIndex += 1\n",
    "    \n",
    "# print (spacyScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMMENT:  For pizza you should check out a Big Mario's. My partner is from the east coast and she hates all of our pizza except for there and Hot Mama's.\n",
      "(PERSON Mario/NNP)\n",
      "(PERSON Hot/NNP Mama/NNP)\n",
      "\n",
      "COMMENT:  BBQ for me would be Jacks BBQ or Radiator Whiskey. Tacos I would head to Tacos Chukis. Burgers I would go to Uneeda. Pizza is a toss up, if you want deep dish try Kylies in Fremont, for thin crust there are millions but Albi room is my personal favorite.  Coffee is Victrola by a longshot.  Donuts is Mighty O all the way.   I am not a huge dessert person but Molly Moons is always high on my ice cream list. \n",
      "\n",
      "(ORGANIZATION BBQ/NNP Radiator/NNP Whiskey/NNP)\n",
      "(PERSON Tacos/NNP Chukis/NNP)\n",
      "(PERSON Uneeda/NNP)\n",
      "(GPE Pizza/NNP)\n",
      "(PERSON Kylies/NNP Fremont/NNP)\n",
      "(PERSON Albi/NNP)\n",
      "(PERSON Coffee/NNP)\n",
      "(ORGANIZATION Victrola/NNP)\n",
      "(PERSON Donuts/NNP)\n",
      "(PERSON Mighty/NNP O/NNP)\n",
      "(PERSON Molly/NNP Moons/NNP)\n",
      "\n",
      "COMMENT:  BBQ - Wood Shop BBQ on Jackson\n",
      "\n",
      "Burgers - Red Mill\n",
      "\n",
      "Mexican (Tacos) - Tacos El Asadero\n",
      "\n",
      "Pizza - Sizzle Pie\n",
      "\n",
      "(ORGANIZATION BBQ/NNP)\n",
      "(PERSON Wood/NN Shop/NNP)\n",
      "(PERSON Jackson/NNP Burgers/NNP)\n",
      "(PERSON Red/NNP Mill/NNP Mexican/NNP)\n",
      "(ORGANIZATION Tacos/NNP)\n",
      "(PERSON Tacos/NN El/NNP Asadero/NNP Pizza/NNP)\n",
      "(PERSON Sizzle/NNP Pie/NNP)\n",
      "\n",
      "COMMENT:  I wouldn't use Austin categories.  Different place, I wouldn't even put BBQ or breakfast tacos in there.  You gotta include pho, sushi, Thai, and maybe Indian.  \n",
      "\n",
      "Anyway...\n",
      "\n",
      "Burgers:  Zippy's\n",
      "\n",
      "Mexican:  Fonda la Catarina\n",
      "\n",
      "Pizza:  Pagliacci (too bad Red Star closed)\n",
      "\n",
      "Coffee:  Uptown Espresso\n",
      "\n",
      "Hot Dogs:  blech\n",
      "\n",
      "Dessert:  Full Tilt ice cream! \n",
      "\n",
      "Now to the real categories: \n",
      "\n",
      "Pho:  Pho 99 or Pho Hi-Ho\n",
      "\n",
      "Sushi:  Shiro's \n",
      "\n",
      "Thai:  dunno\n",
      "\n",
      "Indian:  I've heard the best places are on the East side and I don't ever go there.\n",
      "\n",
      "\n",
      "(GPE Austin/JJ)\n",
      "(ORGANIZATION BBQ/NNP)\n",
      "(GPE Thai/NNP)\n",
      "(GPE Indian/JJ)\n",
      "(PERSON Zippy/NNP)\n",
      "(GPE Mexican/JJ)\n",
      "(ORGANIZATION Catarina/NNP)\n",
      "(PERSON Uptown/JJ Espresso/NNP Hot/NNP Dogs/NNP)\n",
      "(PERSON Full/NNP Tilt/NNP)\n",
      "(PERSON Shiro/NNP)\n",
      "(GPE Thai/NN)\n",
      "(GPE Indian/JJ)\n",
      "(GPE East/NNP)\n",
      "\n",
      "COMMENT:  Check out Jack's BBQ on Airport Way!\n",
      "(PERSON Check/NNP)\n",
      "(PERSON Jack/NNP)\n",
      "(ORGANIZATION BBQ/NNP Airport/NNP Way/NNP)\n"
     ]
    }
   ],
   "source": [
    "#TODO: try on one comment first \n",
    "\n",
    "commentIndex = 0\n",
    "while commentIndex < 5: \n",
    "    \n",
    "    dummyComment = testComments[commentIndex].body\n",
    "    print(\"\\nCOMMENT: \", dummyComment)\n",
    "    dummyComment = ' '.join([word for word in dummyComment.split() if word not in stop])\n",
    "    sentences = nltk.sent_tokenize(dummyComment)\n",
    "\n",
    "    #tokenizes sentences into words --> sentences will become a 2D list [ [blah, blah, blah], [blah, blah, blah] ]\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "    #tags each word in a sentence with a \"part of speech\" label --> sentences will become a 2D list with tuples \n",
    "    # --> [ [ (blah, yuh), (blah, yuh), (blah, yuh) ], [ (blah, yuh), (blah, yuh), (blah, yuh) ] ]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "\n",
    "    #stuff here \n",
    "    for tagged_sentence in sentences: \n",
    "        for chunk in nltk.ne_chunk(tagged_sentence): \n",
    "            if type(chunk) == nltk.tree.Tree:\n",
    "                print (chunk)\n",
    "                \n",
    "    commentIndex += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6n9xbi', '7qw2px', '8l3nru', '832o6u', '8disgf']\n",
      "ITEM: Hot Mama's  SCORE: 6\n",
      "ITEM: Radiator Whiskey  SCORE: 4\n",
      "ITEM: Tacos Chukis  SCORE: 4\n",
      "ITEM: Kylies  SCORE: 4\n",
      "ITEM: Donuts  SCORE: 4\n",
      "ITEM: Molly Moons  SCORE: 4\n",
      "ITEM: Sushi Kashiba  SCORE: 13\n",
      "ITEM: Shiro Kashiba's  SCORE: 13\n",
      "ITEM: Thai Tom - $  SCORE: 13\n",
      "ITEM: Stacia  SCORE: 13\n",
      "ITEM: Pagliacci Pizza - $  SCORE: 13\n",
      "ITEM: Roccos Pizza  SCORE: 3\n",
      "ITEM: Masonry Pizza  SCORE: 3\n",
      "ITEM: Pub  SCORE: 3\n",
      "ITEM: Gourmet Noodle Bowl  SCORE: 29\n",
      "ITEM: Jebena Cafe  SCORE: 29\n",
      "ITEM: Caesar  SCORE: 4\n",
      "ITEM: Roosevelt  SCORE: 23\n",
      "ITEM: Glo  SCORE: 10\n",
      "ITEM: Pete  SCORE: 10\n",
      "ITEM: Kau Kau - Underrated   \n",
      "  SCORE: 13\n"
     ]
    }
   ],
   "source": [
    "#holds item & upvote score \n",
    "items = [] \n",
    "\n",
    "#gets the specified number of posts & comments \n",
    "numPosts = 5 \n",
    "numComments = 3\n",
    "postIDs = postIDs[0:numPosts]\n",
    "print (postIDs)\n",
    "\n",
    "#iterates through posts \n",
    "for postID in postIDs: \n",
    "    \n",
    "    post = reddit.submission(postID)\n",
    "    comments = post.comments[0:numComments]\n",
    "    \n",
    "    #iterates through comments & extracts relevant entities \n",
    "    for comment in comments: \n",
    "        commentNLP = nlp(comment.body)\n",
    "        \n",
    "        for ent in commentNLP.ents: \n",
    "            if ent.label_ == \"PERSON\": \n",
    "                data = (ent.text, comment.score)\n",
    "                items.append(data)\n",
    "        \n",
    "#         print (\"COMMENT:\", comment.score)\n",
    "\n",
    "for item in items: \n",
    "    print (\"ITEM:\", item[0], \" SCORE:\", item[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# testPostID = postIDs[0]\n",
    "# testPost = reddit.submission(testPostID)\n",
    "# print (\"POST ID: \" + testPostID)\n",
    "\n",
    "# #gets top 5 comments from the test Post \n",
    "# commentID = 0 \n",
    "# testComments = testPost.comments[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
